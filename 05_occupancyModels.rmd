---
editor_options: 
  chunk_output_type: console
---

# Occupancy modelling 

## Load necessary libraries
```{r load_libraries, eval=FALSE, message=FALSE, warning=FALSE}

# Load libraries
library(auk)
library(lubridate)
library(sf)
library(unmarked)
library(raster)
library(ebirdst)
library(MuMIn)
library(AICcmodavg)
library(fields)
library(tidyverse)
library(doParallel)
library(snow)
library(openxlsx)
library(data.table)
library(dplyr)
library(ecodist)

# Source necessary functions
source("code/fun_screen_cor.R")
source("code/fun_model_estimate_collection.r")

```

## Load dataframe and scale covariates

Here, we load the required dataframe that contains 10 random visits to a site. Please note that this process is repeated for each dataframe where environmental covariates were prepared at a spatial scale of 2.5 and 10 sq.km around each unique locality. We also scaled all covariates (mean around 0 and standard deviation of 1)

```{r load_dataframe, eval=FALSE}
# Load in the prepared dataframe that contains 10 random visits to each site
dat <- fread("C:\\Occupancy Runs\\dataCovars_2.5km.csv",header=T)
setDF(dat)
head(dat)

# Some more pre-processing to get the right data structures

# Ensuring that only Traveling and Stationary checklists were considered
names(dat)
dat <- dat %>% filter(protocol_type=="Traveling" | protocol_type=="Stationary")

# We take all stationary counts and give them a distance of 100 m (so 0.1 km),
# as that's approximately the max normal hearing distance for people doing point counts.
dat <- dat %>% 
  mutate(effort_distance_km = replace(effort_distance_km, which(effort_distance_km==0 & protocol_type == "Stationary"), 0.1))

# Converting time observations started to numeric and adding it as a new column
# This new column will be minute_observations_started
dat <- dat %>%
  mutate(min_obs_started= strtoi(as.difftime(time_observations_started, format = "%H:%M:%S", units = "mins")))

# Adding the julian date to the dataframe
dat <- dat %>% mutate(julian_date = lubridate::yday(dat$observation_date))

# Removing other unnecessary columns from the dataframe and creating a clean one without the rest
names(dat)
dat <- dat[,-c(1,4,5,16,18,21,23)] 

# Rename column names:
names(dat) <- c("duration_minutes", "effort_distance_km","locality", "locality_type",
                  "locality_id", "observer_id", "observation_date", "scientific_name", "observation_count", "protocol_type",
                  "number_observers","pres_abs","tot_effort","longitude", "latitude","expertise",
                  "alt.y","slope.y","aspect.y","bio_4.y","bio_17.y","bio_18.y","prec_interannual.y","temp_interannual.y",
                  "lc_01.y", "lc_02.y", "lc_03.y","lc_06.y", "lc_07.y","lc_04.y", "lc_05.y",
                  "min_obs_started", "julian_date")

dat.1 <- dat %>% 
  mutate(year = year(observation_date),
         pres_abs = as.integer(pres_abs)) # occupancy modeling requires an integer response

# Scaling detection and occupancy covariates
dat.scaled <- dat.1
dat.scaled[,c(1,2,11,16:33)] <- scale(dat.scaled[,c(1,2,11,16:33)]) # Scaling and standardizing detection and site-level covariates
fwrite(dat.scaled, file = "C:\\Occupancy Runs\\scaledCovs_2.5km.csv")

dat.scaled <- fread("C:\\Occupancy Runs\\scaledCovs_10km.csv",header=T)
setDF(dat.scaled)
head(dat.scaled)

# Testing for correlations before running further analyses

names(dat.scaled)
screen.cor(dat.scaled[,c(1,2,16:33)], threshold = 0.5)

# Removing predictors that are highly correlated with one another
# At a spatial scale of 2.5km, bio_4.y was removed and at a spatial scale of 10km,
# bio_4.y and bio_17.y were removed

dat.scaled <- dat.scaled[,c(1:19,22:34)]
names(dat.scaled)

# Split data by species
list_of_species <- split(x=dat.scaled, f=dat.scaled$scientific_name)

```

## Setting up observation covariates for each model as they remain consistent

```{r obs_covs, eval=FALSE}

# Load obs covs
obs_covs <- c("min_obs_started", 
                "duration_minutes", 
                "effort_distance_km", 
                "number_observers", 
                "protocol_type",
                "expertise",
                "julian_date")

# Detection terms are fixed across occupancy models
  det_terms <- c("p(duration_minutes)","p(effort_distance_km)", "p(expertise)","p(julian_date)","p(min_obs_started)",
  "p(number_observers)","p(protocol_type)")

```


Here, we identify the top models for each species

```{r top_models, eval=FALSE}

# Getting a list of top models for each species

list_of_models_per_species <-  map(list_of_species, function(df){
  
   df <- bind_rows(df)

     # Preparing data for the unmarked model
  occ <- filter_repeat_visits(df, 
                              min_obs = 1, max_obs = 10,
                              annual_closure = FALSE,
                              n_days = 2200, # 6 years is considered a period of closure
                              date_var = "observation_date",
                              site_vars = c("locality_id"))
  
  # format for unmarked
  # The site_covs have to be varied across spatial scales
  occ_wide <- format_unmarked_occu(occ, 
                                   site_id = "site", 
                                   response = "pres_abs",
                                   site_covs = c("locality_id","lc_01.y","lc_02.y","lc_03.y","lc_04.y",                                "lc_05.y", "lc_06.y", "lc_07.y","bio_18.y","alt.y","aspect.y","slope.y",
                                "prec_interannual.y","temp_interannual.y"),obs_covs = obs_covs)
  
  # Convert this dataframe of observations into an unmarked object to start fitting occupancy models
  occ_um <- formatWide(occ_wide, type = "unmarkedFrameOccu")
  
  # Fit a global model with all detection level covariates
  global_det <- occu(~ min_obs_started+
                    julian_date +
                    duration_minutes + 
                    effort_distance_km + 
                    number_observers + 
                    protocol_type +
                    expertise ~ 1, data = occ_um)
  
  # Fit a global land cover model with all detection level covariates
  model_lc <- occu(~min_obs_started+
                   julian_date +
                   duration_minutes + 
                   effort_distance_km + 
                   number_observers + 
                   protocol_type +
                   expertise~lc_01.y+lc_02.y+lc_03.y+lc_04.y+
                   lc_05.y+ lc_06.y+ lc_07.y, data = occ_um)
  
  # Fit a global model with all climate associated predictors 
  model_clim <- occu(~min_obs_started+
                   julian_date +
                   duration_minutes + 
                   effort_distance_km + 
                   number_observers + 
                   protocol_type +
                   expertise~ bio_18.y +  
                   prec_interannual.y + temp_interannual.y, data = occ_um)
  
  # Fit a global model with all elevation associated predictors
  model_elev <- occu(~min_obs_started+
                     julian_date +
                     duration_minutes + 
                     effort_distance_km + 
                     number_observers + 
                     protocol_type +
                     expertise~alt.y + slope.y +aspect.y , data = occ_um)
  
  # Landcover:Elevation - Fit a global model with grasslands, forests, plantations and tea
  model_lc1_elev <- occu(~min_obs_started+
                     julian_date +
                     duration_minutes + 
                     effort_distance_km + 
                     number_observers + 
                     protocol_type +
                     expertise~lc_03.y*alt.y+lc_02.y*alt.y+lc_04.y*alt.y+
                     lc_06.y*alt.y, data = occ_um)
  
  # Landcover:Elevation - Fit a global model with agriculture, settlements and waterbodies
  model_lc2_elev <- occu(~min_obs_started+
                     julian_date +
                     duration_minutes + 
                     effort_distance_km + 
                     number_observers + 
                     protocol_type +
                     expertise~lc_01.y*alt.y+lc_05.y*alt.y+ lc_07.y*alt.y, data = occ_um)
  
  # Fit a global model with climate associated predictors (bio_4,bio_17,bio_18,prec_interannual)
  model_clim_elev <- occu(~min_obs_started+
                       julian_date +
                       duration_minutes + 
                       effort_distance_km + 
                       number_observers + 
                       protocol_type +
                       expertise~bio_18.y*alt.y +  
                       prec_interannual.y*alt.y, data = occ_um)
  
  # Fit a global model with all landcover and climate associated predictors
  model_lc_clim <- occu(~min_obs_started+
                      julian_date +
                      duration_minutes + 
                      effort_distance_km + 
                      number_observers + 
                      protocol_type +
                      expertise~lc_01.y + lc_02.y +lc_03.y + lc_04.y + lc_05.y + lc_06.y + 
                        lc_07.y+ prec_interannual.y +
                        temp_interannual.y, data = occ_um)
        
  # Set up the cluster
  clusterType <- if(length(find.package("snow", quiet = TRUE))) "SOCK" else "PSOCK"
  clust <- try(makeCluster(getOption("cl.cores", 4), type = clusterType))
  
  clusterEvalQ(clust, library(unmarked))
  clusterExport(clust, "occ_um")
  
  # Dredging 
  all_det <- pdredge(global_det, clust) 
  all_lc <- pdredge(model_lc, clust, fixed=det_terms)
  all_clim <- pdredge(model_clim, clust, fixed = det_terms)
  all_elev <- pdredge(model_elev, clust, fixed = det_terms)
  all_lc1_elev <- pdredge(model_lc1_elev, clust, fixed = det_terms)
  all_lc2_elev <- pdredge(model_lc2_elev, clust, fixed = det_terms)
  all_clim_elev <- pdredge(model_clim_elev, clust, fixed = det_terms)
  all_lc_clim <- pdredge(model_lc_clim, clust, fixed = det_terms)
  
  # Get the top models, which we'll define as those with deltaAICc < 2
  top_det <- get.models(all_det, subset = delta < 2, cluster = clust)
  top_lc <- get.models(all_lc, subset = delta < 2, cluster = clust)
  top_clim <- get.models(all_clim, subset = delta < 2, cluster = clust)
  top_elev <- get.models(all_elev, subset = delta < 2, cluster = clust)
  top_lc1_elev <- get.models(all_lc1_elev, subset = delta < 2, cluster = clust)
  top_lc2_elev <- get.models(all_lc2_elev, subset = delta < 2, cluster = clust)
  top_clim_elev <- get.models(all_clim_elev, subset = delta < 2, cluster = clust)
  top_lc_clim <- get.models(all_lc_clim, subset = delta < 2, cluster = clust)
  
  return_data <- list(top_det, top_lc, top_clim, top_elev, top_lc1_elev,
                      top_lc2_elev, top_clim_elev,top_lc_clim)
  
  names(return_data) <- c("Top Detection Models","Top LandCover Models",
                          "Top Climate Models","Top Elevation Models",
                          "Top Landcover1*Elevation Models","Top Landcover2*Elevation Models",
                          "Top Climate*Elevation Models","Top LandCover+Climate Models")
  
  return(return_data)
  
  stopCluster(clust)
})

```


# Use purrr::modify_depth() to get the AIC values for the top models

```{r}

# Unable to get the modify_depth to work
?modify_depth

trial <- list_of_models_per_species[1]

list_of_AIC_per_species <- map(list_of_models_per_species, function(x){
  
  a <- modify_depth(x,3, min)
  return(a)
  
})

  

```

