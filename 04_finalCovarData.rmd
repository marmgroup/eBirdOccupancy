---
editor_options: 
  chunk_output_type: console
---

# Add covariates to subsampled data

## Prepare libraries and data

```{r load_libs_data, eval=FALSE, message=FALSE, warning=FALSE}

# load libs
library(dplyr); library(readr)
library(stringr)
library(purrr)
library(raster)
library(glue)
library(velox)
library(tidyr)
library(sf)

# load saved data object
load("data_prelim_processing.rdata")
```

## Subsample data

Get 10 random (if available) observations of each species at each locality.
**Only 1000 samples used as an example.**

```{r subsample_data, eval=FALSE}
# subsample data for random 10 observations
dataSubsample <- dataGrouped %>%
  
  # sample_n(1e3) %>% # SAMPLING 1000 AS AN EXAMPLE
  
  plyr::dlply(c("scientific_name", "locality_id")) %>% 
  map_if(function(x) nrow(x) > 10, function(x) sample_n(x, 10, replace = FALSE)) %>% 
  bind_rows()

# remove full data
rm(dataGrouped)
```

## Add expertise score

```{r add_expertise, eval=FALSE}
# read in obs score and extract numbers
expertiseScore <- read_csv("data/dataObsExpScore.csv") %>% 
  mutate(numObserver = str_extract(observer, "\\d+")) %>% 
  dplyr::select(-observer)

# group seis consist of multiple observers
# in this case, seis need to have the highest expertise observer score
# as the associated covariate

# get unique observers per sei
dataSeiScore <- distinct(dataSubsample, sampling_event_identifier, observer_id) %>% 
  # make list column of observers
  mutate(observers = str_split(observer_id, ",")) %>% 
  unnest(cols = c(observers)) %>% 
  # add numeric observer id
  mutate(numObserver = str_extract(observers, "\\d+")) %>% 
  # now get distinct sei and observer id numeric
  distinct(sampling_event_identifier, numObserver)

# now add expertise score to sei
dataSeiScore <- left_join(dataSeiScore, expertiseScore,
                          by="numObserver") %>% 
  # get max expertise score per sei
  group_by(sampling_event_identifier) %>% 
  summarise(expertise = max(rptrScore))

# add to dataCovar
dataSubsample <- left_join(dataSubsample, dataSeiScore, 
                           by = "sampling_event_identifier")

# remove data without expertise score
dataSubsample <- filter(dataSubsample, !is.na(expertise))

```

## Add landscape covariates

```{r add_landcovars, eval=FALSE}

# list landscape covariate stacks
landscape_files <- "data/spatial/landscape_resamp01km.tif"

# read in as stacks
landscape_data <- stack(landscape_files)

# get proper names
elev_names <- c("elev", "slope", "aspect")
evi_names <- c("evi_01", "evi_07", "evi_10")
chelsa_names <- c("chelsa_bio10_04", "chelsa_bio10_17", "chelsa_bio10_18",
                  "chelsa_prec", "chelsa_temp")

names(landscape_data) <- as.character(glue('{c(elev_names, evi_names, chelsa_names, "landcover")}'))
```

## Construct 2.5km buffer around subsampled points

```{r point_buffer, eval=FALSE}
# assign neighbourhood radius in m
sample_radius <- c(2.5, 10, 25) * 1e3

# get distinct points and make buffer
ebird_buff <- dataSubsample %>% 
  distinct(locality_id, latitude, longitude) %>% 
  mutate(id = 1:nrow(.)) %>% 
  crossing(sample_radius) %>% 
  group_by(sample_radius) %>% 
  nest() %>% 
  ungroup()


# convert to spatial features
ebird_buff <- mutate(ebird_buff, 
                     data = map2(data, sample_radius, 
                                 function(df,rd){
  df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326) %>% 
    # transform to modis projection
    st_transform(crs = 32643) %>% 
    # buffer to create neighborhood around each point
    st_buffer(dist = rd)
}))
```

## Getting area means

### Mean environmental covariates

All covariates are 2.5km mean values and prefixed "am_".

```{r mean_landscape, eval=FALSE}
# get area mean for all preds except landcover, which is the last one
env_area_mean <- purrr::map(ebird_buff$data, function(df){
  
  stk <- landscape_data[[-dim(landscape_data)[3]]] # removing landcover here
  velstk <- velox(stk)
  dextr <- velstk$extract(sp = df, df = TRUE, 
                          fun = function(x)mean(x, na.rm=T))
  
  # assign names for joining
  names(dextr) <- c("id", names(stk))
  return(as_tibble(dextr))
})

# join to buffer data
ebird_buff <- ebird_buff %>% 
  mutate(data = map2(data, env_area_mean, inner_join, by = "id"))

```

### Proportional landcover

```{r pland, eval=FALSE}
# get the last element of each stack from the list
# this is the landcover at that resolution
lc_area_prop <- purrr::map(ebird_buff$data, function(df){
  lc <- landscape_data[[dim(landscape_data)[3]]] # accessing landcover here
  lc_velox <- velox(lc)
  lc_vals <- lc_velox$extract(sp = df, df = TRUE)
  names(lc_vals) <- c("id", "lc")
  
  # get landcover proportions
  lc_prop <- count(lc_vals, id, lc) %>% 
    group_by(id) %>%
    mutate(lc = glue('lc_{str_pad(lc, 2, pad = "0")}'), 
           prop = n/sum(n)) %>% 
    dplyr::select(-n) %>% 
    tidyr::pivot_wider(names_from = lc, 
                       values_from = prop, 
                       values_fill = list(prop = 0)) %>% 
    ungroup()
  
  return(lc_prop)
})

# join to data
ebird_buff <- ebird_buff %>% 
  mutate(data = map2(data, lc_area_prop, inner_join, by = "id"))
```

## Join landscape data to obs data

```{r land_to_obs, eval=FALSE}
# duplicate scale data
data_at_scale <- ebird_buff

# join the full data to landscape samples at each scale
data_at_scale$data <- map(data_at_scale$data, function(df){
  df <- st_drop_geometry(df)
  df <- inner_join(dataSubsample, df, by="locality_id")
  return(df)
})

```


## Write data to files

```{r spit_scale, eval=FALSE}
# write to file
pmap(data_at_scale, function(sample_radius, data){
  write_csv(data, path = glue('data/dataCovars_{str_pad(sample_radius/1e3, 2, pad = "0")}km.csv'))
  return("export done")
})

```

