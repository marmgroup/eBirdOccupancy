---
editor_options: 
  chunk_output_type: console
---

# Add covariates to subsampled data

## Prepare libraries and data

```{r load_libs_data, eval=FALSE, message=FALSE, warning=FALSE}

# load libs
library(dplyr); library(readr)
library(stringr)
library(purrr)
library(raster)
library(glue)
library(velox)
library(tidyr)
library(sf)

# load saved data object
load("data_prelim_processing.rdata")
```

## Subsample data

Get 10 random (if available) observations of each species at each locality.
**Only 1000 samples used as an example.**

```{r subsample_data, eval=FALSE}
# subsample data for random 10 observations
dataSubsample <- dataGrouped %>%
  
  # sample_n(1e3) %>% # SAMPLING 1000 AS AN EXAMPLE
  
  plyr::dlply(c("scientific_name", "locality_id")) %>% 
  map_if(function(x) nrow(x) > 10, function(x) sample_n(x, 10, replace = FALSE)) %>% 
  bind_rows()

# remove full data
rm(dataGrouped)
```

## Add expertise score

```{r add_expertise, eval=FALSE}
# read in obs score and extract numbers
expertiseScore <- read_csv("data/dataObsRptrScore.csv") %>% 
  mutate(numObserver = str_extract(observer, "\\d+")) %>% 
  dplyr::select(-observer)

# group seis consist of multiple observers
# in this case, seis need to have the highest expertise observer score
# as the associated covariate

# get unique observers per sei
dataSeiScore <- distinct(dataSubsample, sampling_event_identifier, observer_id) %>% 
  # make list column of observers
  mutate(observers = str_split(observer_id, ",")) %>% 
  unnest(cols = c(observers)) %>% 
  # add numeric observer id
  mutate(numObserver = str_extract(observers, "\\d+")) %>% 
  # now get distinct sei and observer id numeric
  distinct(sampling_event_identifier, numObserver)

# now add expertise score to sei
dataSeiScore <- left_join(dataSeiScore, expertiseScore,
                          by="numObserver") %>% 
  # get max expertise score per sei
  group_by(sampling_event_identifier) %>% 
  summarise(expertise = max(rptrScore))

# add to dataCovar
dataSubsample <- left_join(dataSubsample, dataSeiScore, 
                           by = "sampling_event_identifier")

# remove data without expertise score
dataSubsample <- filter(dataSubsample, !is.na(expertise))

```

## Add landscape covariates

```{r add_landcovars, eval=FALSE}

# list landscape covariate stacks
landscape_files <- "data/spatial/landscape_resamp01km.tif"

# read in as stacks
landscape_data <- stack(landscape_files)

# get proper names
elev_names <- c("elev", "slope", "aspect")
evi_names <- c("evi_01", "evi_07", "evi_10")
chelsa_names <- c("chelsa_bio10_04", "chelsa_bio10_17", "chelsa_bio10_18",
                  "chelsa_prec", "chelsa_temp")

names(landscape_data) <- as.character(glue('{c(elev_names, evi_names, chelsa_names, "landcover")}'))
```

## Construct 2.5km buffer around subsampled points

```{r point_buffer, eval=FALSE}
# assign neighbourhood radius in m
sample_radius <- c(2.5, 10, 25) * 1e3

# get distinct points and make buffer
ebird_buff <- dataSubsample %>% 
  distinct(locality_id, latitude, longitude) %>% 
  mutate(id = 1:nrow(.)) %>% 
  crossing(sample_radius) %>% 
  group_by(sample_radius) %>% 
  nest() %>% 
  ungroup()


# convert to spatial features
ebird_buff <- mutate(ebird_buff, 
                     data = map2(data, sample_radius, 
                                 function(df,rd){
  df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326) %>% 
    # transform to modis projection
    st_transform(crs = 32643) %>% 
    # buffer to create neighborhood around each point
    st_buffer(dist = rd)
}))
```

## Getting area means

### Mean environmental covariates

All covariates are 2.5km mean values and prefixed "am_".

```{r mean_landscape, eval=FALSE}
# get area mean for all preds except landcover, which is the last one
env_area_mean <- purrr::map(landscape_data, function(stk){
  stk <- stk[[-dim(stk)[3]]] # removing landcover here
  velstk <- velox(stk)
  dextr <- velstk$extract(sp = ebird_buff, df = TRUE, 
                          fun = function(x)mean(x, na.rm=T))
  
  # assign names for joining
  names(dextr) <- c("id", names(stk))
  return(as_tibble(dextr))
})

# run a reduce leftjoin on the data
env_area_mean <- purrr::reduce(env_area_mean, left_join, by="id")
# rename to be clear which are mean-area vars
temp_names <- str_split(names(env_area_mean), "resamp") %>% map(function(x)x[2])
names(env_area_mean) <- c("id", glue::glue('am_{temp_names[-1]}'))
```

### Proportional landcover

```{r pland, eval=FALSE}
# get the last element of each stack from the list
# this is the landcover at that resolution
lc_area_prop <- purrr::map(landscape_data, function(stk){
  lc <- stk[[dim(stk)[3]]] # accessing landcover here
  lc_velox <- velox(lc)
  lc_vals <- lc_velox$extract(sp = ebird_buff, df = TRUE)
  names(lc_vals) <- c("id", "lc")
  
  # temporary names here as well
  temp_name <- str_split(names(lc), "resamp") %>% map_chr(function(x) x[2])
  
  # get landcover proportions
  lc_prop <- count(lc_vals, id, lc) %>% 
    group_by(id) %>%
    mutate(lc = glue('am_{temp_name}_{str_pad(lc, 2, pad = "0")}'), 
           prop = n/sum(n)) %>% 
    dplyr::select(-n) %>% 
    tidyr::pivot_wider(names_from = lc, 
                       values_from = prop, 
                       values_fill = list(prop = 0))
  
  return(lc_prop)
})

lc_area_prop <- reduce(lc_area_prop, left_join, by="id")

```

## Add landscape covariates

```{r add_land_covars, eval=FALSE}
# link back to rand10 via ebird buff using coordinate id
# drop geometry and assign id column
ebird_buff <- ebird_buff %>% 
  st_drop_geometry() %>% 
  mutate(id = 1:nrow(.)) %>% 
  # merge on id
  left_join(lc_prop, by = "id") %>%
  left_join(env_area_mean, by = "id")

# join to random 10 dataset on locality id
dataSubsample <- left_join(dataSubsample, ebird_buff,
                            by = "locality_id")

```

## Write random 10 with covariates

```{r write_final_covars, eval=FALSE}
# write using write_csv
write_csv(dataSubsample, "data/dataRand10_withLC.csv")
```

