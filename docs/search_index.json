[
["index.html", "Influence of land cover and climate on the occupancy of avian distributions along a tropical montane gradient Section 1 Introduction 1.1 Attribution 1.2 Data access 1.3 Data processing", " Influence of land cover and climate on the occupancy of avian distributions along a tropical montane gradient Vijay Ramesh, Pratik R Gupte, and Morgan Tingley 2019-12-22 Section 1 Introduction This is the bookdown version of a project in preparation that models occupancy for birds in the Nilgiri hills. Methods and format are derived from Strimas-Mackey et al., the supplement to Jonhnston et al.Â (2019). 1.1 Attribution Please contact the following in case of interest in the project. Vijay Ramesh (lead author) PhD student, Columbia University Pratik Gupte (repo maintainer) PhD student, University of Groningen Morgan Tingley (PI) 1.2 Data access The data used in this work are available from eBird. 1.3 Data processing The data processing for this project is described in the following sections. Navigate through them using the links in the sidebar. "],
["preparing-ebird-data.html", "Section 2 Preparing eBird data 2.1 Prepare libraries and data sources 2.2 Filter data 2.3 Process filtered data 2.4 Spatial filter 2.5 Handle presence data 2.6 Add decimal time 2.7 Write data", " Section 2 Preparing eBird data 2.1 Prepare libraries and data sources # load libs library(tidyverse) library(readr) library(sf) library(auk) library(readxl) # custom sum function sum.no.na &lt;- function(x){sum(x, na.rm = T)} #set file paths for auk functions f_in_ebd &lt;- file.path(&quot;ebd_Filtered_Jun2019.txt&quot;) f_in_sampling &lt;- file.path(&quot;ebd_sampling_Filtered_Jun2019.txt&quot;) 2.2 Filter data # add species of interest specieslist &lt;- read_excel(&quot;data/species_list_13_11_2019.xlsx&quot;) speciesOfInterest &lt;- specieslist$scientific_name # run filters using auk packages ebd_filters &lt;- auk_ebd(f_in_ebd, f_in_sampling) %&gt;% auk_species(speciesOfInterest) %&gt;% auk_country(country = &quot;IN&quot;) %&gt;% auk_state(c(&quot;IN-KL&quot;,&quot;IN-TN&quot;, &quot;IN-KA&quot;)) %&gt;% # Restricting geography to TamilNadu, Kerala &amp; Karnataka auk_date(c(&quot;2013-01-01&quot;, &quot;2018-12-31&quot;)) %&gt;% auk_complete() # check filters ebd_filters Below code need not be run if it has been filtered once already and the above path leads to the right dataset. NB: This is a computation heavy process, run with caution. # specify output location and perform filter f_out_ebd &lt;- &quot;data/eBirdDataWG_filtered.txt&quot; f_out_sampling &lt;- &quot;data/eBirdSamplingDataWG_filtered.txt&quot; ebd_filtered &lt;- auk_filter(ebd_filters, file = f_out_ebd, file_sampling = f_out_sampling, overwrite = TRUE) 2.3 Process filtered data # read in the data ebd &lt;- read_ebd(f_out_ebd) # fill zeroes zf &lt;- auk_zerofill(f_out_ebd, f_out_sampling) new_zf &lt;- collapse_zerofill(zf) # Creates a new zero-filled dataframe with a 0 marked for each checklist when the bird was not observed # choose columns of interest columnsOfInterest &lt;- c(&quot;checklist_id&quot;,&quot;scientific_name&quot;,&quot;observation_count&quot;,&quot;locality&quot;,&quot;locality_id&quot;,&quot;locality_type&quot;,&quot;latitude&quot;,&quot;longitude&quot;,&quot;observation_date&quot;,&quot;time_observations_started&quot;,&quot;observer_id&quot;,&quot;sampling_event_identifier&quot;,&quot;protocol_type&quot;,&quot;duration_minutes&quot;,&quot;effort_distance_km&quot;,&quot;effort_area_ha&quot;,&quot;number_observers&quot;,&quot;species_observed&quot;,&quot;reviewed&quot;) # make list of presence and absence data and choose cols of interest data &lt;- list(ebd, new_zf) %&gt;% map(function(x){ x %&gt;% select(one_of(columnsOfInterest)) }) # remove zerofills to save working memory rm(zf, new_zf); gc() # check presence and absence in absences df, remove essentially the presences df data[[2]] &lt;- data[[2]] %&gt;% filter(species_observed == F) 2.4 Spatial filter # load shapefiles of hill ranges library(sf) hills &lt;- st_read(&quot;data/spatial/hillsShapefile/Nil_Ana_Pal.shp&quot;) # write a prelim filter by bounding box box &lt;- st_bbox(hills) # get data spatial coordinates dataLocs &lt;- data %&gt;% map(function(x){ select(x, longitude, latitude) %&gt;% filter(between(longitude, box[&quot;xmin&quot;], box[&quot;xmax&quot;]) &amp; between(latitude, box[&quot;ymin&quot;], box[&quot;ymax&quot;]))}) %&gt;% bind_rows() %&gt;% distinct() %&gt;% st_as_sf(coords = c(&quot;longitude&quot;, &quot;latitude&quot;)) %&gt;% st_set_crs(4326) %&gt;% st_intersection(hills) # filter data by dataLocs dataLocs &lt;- mutate(dataLocs, spatialKeep = T) %&gt;% dropGeometry() # bind to data and then filter data &lt;- data %&gt;% map(function(x){ left_join(x, dataLocs, by = c(&quot;longitude&quot; = &quot;X&quot;, &quot;latitude&quot; = &quot;Y&quot;)) %&gt;% filter(spatialKeep == T) %&gt;% select(-Id, -spatialKeep) }) # save a temp data file save(data, file = &quot;data.temp.rdata&quot;) 2.5 Handle presence data # in the first set, replace X, for presences, with 1 data[[1]] &lt;- data[[1]] %&gt;% mutate(observation_count = ifelse(observation_count == &quot;X&quot;, &quot;1&quot;, observation_count)) # remove records where duration is 0 data &lt;- map(data, function(x) filter(x, duration_minutes &gt; 0)) # group data by site and sampling event identifier # then, summarise relevant variables as the sum dataGrouped &lt;- map(data, function(x){ x %&gt;% group_by(sampling_event_identifier) %&gt;% summarise_at(vars(duration_minutes, effort_distance_km, effort_area_ha), list(sum.no.na)) }) # bind rows combining data frames, and filter dataGrouped &lt;- bind_rows(dataGrouped) %&gt;% filter(duration_minutes &lt;= 300, effort_distance_km &lt;= 5, effort_area_ha &lt;= 500) # get data identifiers, such as sampling identifier etc dataConstants &lt;- data %&gt;% bind_rows() %&gt;% select(sampling_event_identifier, time_observations_started, locality, locality_type, locality_id, observer_id, observation_date, scientific_name, observation_count, protocol_type, number_observers, longitude, latitude) # join the summarised data with the identifiers, using sampling_event_identifier as the key dataGrouped &lt;- left_join(dataGrouped, dataConstants, by = &quot;sampling_event_identifier&quot;) # remove checklists or seis with more than 10 obervers count(dataGrouped, number_observers &gt; 10) # count how many have 10+ obs dataGrouped &lt;- filter(dataGrouped, number_observers &lt;= 10) 2.6 Add decimal time # assign present or not, and get time in decimal hours since midnight library(lubridate) time_to_decimal &lt;- function(x) { x &lt;- hms(x, quiet = TRUE) hour(x) + minute(x) / 60 + second(x) / 3600 } # will cause issues if using time obs started as a linear effect and not quadratic dataGrouped = mutate(dataGrouped, pres_abs = observation_count &gt;= 1, decimalTime = time_to_decimal(time_observations_started)) # check class of dataGrouped, make sure not sf assertthat::assert_that(!&quot;sf&quot; %in% class(dataGrouped)) 2.7 Write data # save a temp data file save(dataGrouped, file = &quot;data.temp.rdata&quot;) "],
["prepare-landscape-data.html", "Section 3 Prepare landscape data 3.1 Prepare libraries 3.2 Prepare initial data 3.3 Resample rasters 3.4 WIP", " Section 3 Prepare landscape data 3.1 Prepare libraries # load libs library(raster) library(stringi) library(glue) library(gdalUtils) # prep mode function to aggregate funcMode &lt;- function(x, na.rm = T) { ux &lt;- unique(x) ux[which.max(tabulate(match(x, ux)))] } # a basic test assertthat::assert_that(funcMode(c(2,2,2,2,3,3,3,4)) == as.character(2), msg = &quot;problem in the mode function&quot;) # works 3.2 Prepare initial data 3.2.1 Prepare spatial extent # load hills library(sf) hills &lt;- st_read(&quot;data/spatial/hillsShapefile/Nil_Ana_Pal.shp&quot;) 3.2.2 Prepare terrain rasters # load elevation and crop to hills size, then mask by hills alt &lt;- raster(&quot;data/spatial/Elevation/alt&quot;) alt.hills &lt;- crop(alt, as(hills, &quot;Spatial&quot;)) rm(alt); gc() # get slope and aspect slopeData &lt;- terrain(x = alt.hills, opt = c(&quot;slope&quot;, &quot;aspect&quot;)) elevData &lt;- raster::stack(alt.hills, slopeData) rm(alt.hills); gc() 3.2.3 Prepare EVI rasters # load evi layers evi &lt;- raster::stack(&quot;data/spatial/EVI/MOD13Q1_EVI_AllYears.tif&quot;)[[c(1,7,10)]] # reproject to elevdata evi &lt;- projectRaster(evi, elevData, res(elevData)) 3.2.4 Prepare CHELSA rasters # list chelsa files chelsaFiles &lt;- list.files(&quot;data/chelsa/&quot;, full.names = TRUE, pattern = &quot;crop.tif&quot;) # gather chelsa rasters chelsaData &lt;- purrr::map(chelsaFiles, function(chr){ a &lt;- raster(chr) crs(a) &lt;- crs(evi) return(a) }) # stack chelsa data chelsaData &lt;- raster::stack(chelsaData) # project to elevation chelsaData &lt;- projectRaster(chelsaData, elevData, res(elevData)) 3.2.5 Stack prepared rasters # stack rasters for efficient reprojection later env_data &lt;- stack(elevData, evi, chelsaData) 3.2.6 Prepare landcover # read in landcover raster location landcover &lt;- &quot;data/landUseClassification/ClassifiedImage_31stAug_UTM34N_Ghats.tif&quot; # get extent e = bbox(raster(landcover)) # use gdalutils gdalwarp for resampling transform # to 1km from 10m gdalwarp(srcfile = landcover, dstfile = &quot;data/landUseClassification/lc_01km.tif&quot;, tr=c(1000,1000), r=&#39;mode&#39;, te=c(e)) # to 10km from 1km gdalwarp(srcfile = &quot;data/landUseClassification/lc_01km.tif&quot;, dstfile = &quot;data/landUseClassification/lc_10km.tif&quot;, tr=c(10000,10000), r=&#39;mode&#39;, te=c(e)) # to 25km from 1km gdalwarp(srcfile = &quot;data/landUseClassification/lc_01km.tif&quot;, dstfile = &quot;data/landUseClassification/lc_25km.tif&quot;, tr=c(25000,25000), r=&#39;mode&#39;, te=c(e)) 3.3 Resample rasters 3.3.1 Read landcover as list Here, we read in the 1km, 10km, and 25km resampled landcover rasters as a list. # list the files and map a raster read over them lc_files &lt;- list.files(&quot;data/landUseClassification/&quot;, pattern = &quot;km.tif&quot;, full.names = TRUE) lc_data &lt;- map(lc_files, raster) 3.3.2 Reproject environmental data to landcover # resample to the corresponding landcover data env_data_resamp &lt;- map(lc_data, function(rs){ projectRaster(from = env_data, to = rs, crs = crs(rs), res = res(rs)) }) # export as raster stack land_stacks &lt;- map2(env_data_resamp, lc_data, function(a, b){ land_stack = stack(a, b)}) # get names land_names &lt;- glue(&#39;data/spatial/landscape_resamp{c(&quot;01&quot;,&quot;10&quot;,&quot;25&quot;)}km.tif&#39;) # write to file map2(land_stacks, land_names, function(x,y){ writeRaster(x, filename = as.character(y)) }) 3.4 WIP "]
]
